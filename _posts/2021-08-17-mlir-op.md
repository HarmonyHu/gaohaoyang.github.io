---
layout: single
title: MLIR的细节整理
categories:
  - AI
tags:
  - Mlir
---

* content
{:toc}


# 概念

以一段来自官网[toy](https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/)，来解释各种概念

```python
# User defined generic function that operates on unknown shaped arguments.
def multiply_transpose(a, b) {
  return transpose(a) * transpose(b);
}

def main() {
  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];
  var b<2, 3> = [1, 2, 3, 4, 5, 6];
  var c = multiply_transpose(a, b);
  var d = multiply_transpose(b, a);
  print(d);
}
```

转成IR定义如下：

<!--more-->

```json
module {
  func @multiply_transpose(%arg0: tensor<*xf64>, %arg1: tensor<*xf64>) -> tensor<*xf64> {
    %0 = "toy.transpose"(%arg0) : (tensor<*xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":5:10)
    %1 = "toy.transpose"(%arg1) : (tensor<*xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":5:25)
    %2 = "toy.mul"(%0, %1) : (tensor<*xf64>, tensor<*xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":5:25)
    "toy.return"(%2) : (tensor<*xf64>) -> () loc("Toy/Ch2/codegen.toy":5:3)
  } loc("Toy/Ch2/codegen.toy":4:1)
  func @main() {
    %0 = "toy.constant"() {value = dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>} : () -> tensor<2x3xf64> loc("Toy/Ch2/codegen.toy":9:17)
    %1 = "toy.reshape"(%0) : (tensor<2x3xf64>) -> tensor<2x3xf64> loc("Toy/Ch2/codegen.toy":9:3)
    %2 = "toy.constant"() {value = dense<[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]> : tensor<6xf64>} : () -> tensor<6xf64> loc("Toy/Ch2/codegen.toy":10:17)
    %3 = "toy.reshape"(%2) : (tensor<6xf64>) -> tensor<2x3xf64> loc("Toy/Ch2/codegen.toy":10:3)
    %4 = "toy.generic_call"(%1, %3) {callee = @multiply_transpose} : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":11:11)
    %5 = "toy.generic_call"(%3, %1) {callee = @multiply_transpose} : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":12:11)
    "toy.print"(%5) : (tensor<*xf64>) -> () loc("Toy/Ch2/codegen.toy":13:3)
    "toy.return"() : () -> () loc("Toy/Ch2/codegen.toy":8:1)
  } loc("Toy/Ch2/codegen.toy":8:1)
} loc(unknown)
```



## mlir::Operation

```json
%2 = "toy.mul"(%0, %1) : (tensor<*xf64>, tensor<*xf64>) -> tensor<*xf64> loc("Toy/Ch2/codegen.toy":5:25)
```

Operation是指操作，也可以理解成运算。如上中`%2 = "toy.mul"(%0,%1)`可以看做一个operation。如toy中的`toy.mul`、`toy.transpose`、`toy.constant`等等都是Operation的名称。

代码中`mlir::Operation`是通用定义，包含通用的接口和属性；`MulOp`、`TransposeOp`、`ConstantOp`等等是特定定义，包含特定的属性。前者可以通过`llvm::dyn_cast`（动态）或`llvm::cast`（静态）转换成后者；后者通过`getOperation()`转换成前者。如下：

``` c++
void processConstantOp(mlir::Operation *operation) {
  ConstantOp op = llvm::dyn_cast<ConstantOp>(operation);

  // This operation is not an instance of `ConstantOp`.
  if (!op)
    return;

  // Get the internal operation instance wrapped by the smart pointer.
  mlir::Operation *internalOperation = op.getOperation();
  assert(internalOperation == operation &&
         "these operation instances are the same");
}
```

特定Op可以直接访问属性；`mlir::Operation`无法直接访问特定Op的属性，但可以类似如下间接访问，如下：

``` c++
// getAttrOfType
IntegerAttr opsetAttr = op->getAttrOfType<::mlir::Attribute>("onnx_opset").dyn_cast_or_null<IntegerAttr>();
if (opsetAttr)
  opset = opsetAttr.getValue().getSExtValue();
// getAttr
mlir::Type targetType = op->getAttr("to").cast<::mlir::TypeAttr>().getValue();
```

`mlir::Operation`有如下常用接口：

```c++
OperationName getName() { return name; }
/// Remove this operation from its parent block and delete it.
void erase();
/// Remove the operation from its parent block, but don't delete it.
void remove();
/// Returns the operation block that contains this operation.
Block *getBlock() { return block; }
/// Return the context this operation is associated with.
MLIRContext *getContext();
void dump();
unsigned getNumOperands();
Value getOperand(unsigned idx) { return getOpOperand(idx).get(); }
void setOperand(unsigned idx, Value value);
unsigned getNumResults();
/// Get the 'idx'th result of this operation.
OpResult getResult(unsigned idx) { return OpResult(this, idx); }
void replaceAllUsesWith(Operation *op);
void moveBefore(Operation *existingOp);
void moveBefore(Block *block, llvm::iplist<Operation>::iterator iterator);
void moveAfter(Operation *existingOp);
void moveAfter(Block *block, llvm::iplist<Operation>::iterator iterator);
```



## mlir::Value

Value可以理解成操作数，参数等等，如例子中的`%arg0`、`%1`。

Value几乎所有接口都非常有用：

``` c++
Type getType() const;
void setType(Type newType);
MLIRContext *getContext() const { return getType().getContext(); }
Location getLoc() const;
Region *getParentRegion();
Block *getParentBlock();
void replaceAllUsesWith(Value newValue) const;
void replaceUsesWithIf(Value newValue, function_ref<bool(OpOperand &)> shouldReplace);
use_range getUses() const { return {use_begin(), use_end()}; }
bool hasOneUse() const;
bool use_empty() const;
void dump();
```

#### BlockArgument

如例子中的`%arg0`、`%arg1`等等

```c++
class BlockArgument : public Value{
  /// Returns the block that owns this argument.
  Block *getOwner() const { return getImpl()->owner; }

  /// Return the type of this value.
  Type getType() const { return getImpl()->type; }

  /// Set the type of this value.
  void setType(Type newType) { getImpl()->type = newType; }

  /// Returns the number of this argument.
  unsigned getArgNumber() const { return getImpl()->index; }
}
```

#### OpResult

如例中的`%0`、`%1`、`%2`等等

``` c++
class OpResult : public Value {
public:
  using Value::Value;

  static bool classof(Value value) {
    return value.getKind() != Kind::BlockArgument;
  }

  /// Returns the operation that owns this result.
  Operation *getOwner() const;

  /// Returns the number of this result.
  unsigned getResultNumber() const;
}
```

通过value，获取operation，如下：

```c++
// %2对应value，则
Operation * operation = value.getDefiningOp();
toy::MulOp op = value.getDefiningOp<toy::MulOp>();
// get Value from operation
Value inner_value = operation->getResult(0);
assert(inner_value == value);
```

## mlir::Block

在`:`之间一系列operation的合集。

有如下这些接口：

``` c++
Region *getParent() const;

/// Returns the closest surrounding operation that contains this block.
Operation *getParentOp();
/// Return if this block is the entry block in the parent region.
bool isEntryBlock();

/// Insert this block (which must not already be in a region) right before
/// the specified block.
void insertBefore(Block *block);

/// Unlink this block from its current region and insert it right before the
/// specific block.
void moveBefore(Block *block);

/// Unlink this Block from its parent region and delete it.
void erase();
BlockArgListType getArguments() { return arguments; }
unsigned getNumArguments() { return arguments.size(); }
BlockArgument getArgument(unsigned i) { return arguments[i]; }
iterator begin() { return operations.begin(); }
iterator end() { return operations.end(); }
Operation &back() { return operations.back(); }
Operation &front() { return operations.front(); }
```



## mlir::Region

在`{}`之间一系列block的合集。

有如下接口：

``` c++
MLIRContext *getContext();

/// Return a location for this region. This is the location attached to the
/// parent container. The region must have a valid parent container.
Location getLoc();

//===--------------------------------------------------------------------===//
// Block list management
//===--------------------------------------------------------------------===//

using BlockListType = llvm::iplist<Block>;
BlockListType &getBlocks() { return blocks; }
iterator begin() { return blocks.begin(); }
iterator end() { return blocks.end(); }
Block &back() { return blocks.back(); }
Block &front() { return blocks.front(); }
unsigned getNumArguments() { return getArguments().size(); }
BlockArgument getArgument(unsigned i) { return getArguments()[i]; }
```



## mlir::Type

Type可以理解成Value的类型，如例子中的`tensor<*xf64>`、`tensor<2x3xf64>`等等对应的是TensorType，继承自`mlir::Type`。

type常用接口有这些：

``` c++
bool operator==(Type other) const { return impl == other.impl; }
bool operator!=(Type other) const { return !(*this == other); }
explicit operator bool() const { return impl; }
bool operator!() const { return impl == nullptr; }
template <typename U> bool isa() const;
template <typename First, typename Second, typename... Rest> bool isa() const;
template <typename U> U dyn_cast() const;
template <typename U> U dyn_cast_or_null() const;
template <typename U> U cast() const;  
bool isIndex() const;
bool isBF16() const;
bool isF16() const;
bool isF32() const;
bool isF64() const;
bool isF80() const;
bool isF128() const;

/// Return true if this is an integer type with the specified width.
bool isInteger(unsigned width) const;
```

#### ShapedType

ShapedType用于表示Shape，有`ranked`和`unranked`之分，ranked在维度上又有`static`和`dynamic`之分。

有如下这些方式：

* `[*]` if it is an unranked shape
* `[?, 2]` if a rank 2 tensor with one unknown dimension
* `[3, 4]` is a rank 2 static tensor
* `[]` is a scalar
* `[1]` is a rank 1 tensor with 1 element
* `[invalid]` for an invalid shape

有如下这些接口，用了Trait：

```c++
class ShapedType : public ::mlir::TypeInterface<ShapedType, detail::ShapedTypeInterfaceTraits> {
public:
  using ::mlir::TypeInterface<ShapedType, detail::ShapedTypeInterfaceTraits>::TypeInterface;
  template <typename ConcreteType>
  struct Trait : public detail::ShapedTypeTrait<ConcreteType> {};
  ::mlir::ShapedType cloneWith(::llvm::Optional<::llvm::ArrayRef<int64_t>> shape, ::mlir::Type elementType) const;
  ::mlir::Type getElementType() const;
  bool hasRank() const;
  ::llvm::ArrayRef<int64_t> getShape() const;
  /// Returns whether the shape has a rank.
  bool hasRank() const;
  /// Returns the element type.
  Type getElementType() const;
  /// Populates the dimensions from shape referenced.
  /// Requires: shape is ranked.
  void getDims(SmallVectorImpl<int64_t> &res) const;
  /// Populates the dimensions of the ShapeTypeComponents.
  /// Requires: shape is ranked.
  void getDims(ShapedTypeComponents &res) const;
  /// Returns the size of the index'th dimension.
  /// Requires: shape is ranked.
  int64_t getDimSize(int index) const;
  /// Returns whether the index'th dimension is dynamic.
  /// Requires: shape is ranked.
  bool isDynamicDim(int index) const { // 判断dimSize是否为kDynamicSize(对应-1)
    return ShapedType::isDynamic(getDimSize(index));
  }
  /// Returns whether the shape is fully static.
  bool hasStaticShape() const;
  /// Returns the rank of the shape.
  /// Requires: shape is ranked.
  int64_t getRank() const;
  /// Returns the number of elements in the shape.
  /// Requires: hasStaticShape
  int64_t getNumElements() const;
```

该类由dialect自动生成：

``` c++
def ShapedTypeInterface : TypeInterface<"ShapedType"> {
  let cppNamespace = "::mlir";
  let description = [{
    ...
```



#### TensorType

如例子中的`tensor<*xf64>`、`tensor<2x3xf64>`等等，是type与ShapeType的子类。

定义如下：

``` c++
class TensorType : public Type, public ShapedType::Trait<TensorType> {
public:
  using Type::Type;

  /// Returns the element type of this tensor type.
  Type getElementType() const;

  /// Returns if this type is ranked, i.e. it has a known number of dimensions.
  bool hasRank() const;

  /// Returns the shape of this tensor type.
  ArrayRef<int64_t> getShape() const;

  /// Clone this type with the given shape and element type. If the
  /// provided shape is `None`, the current shape of the type is used.
  TensorType cloneWith(Optional<ArrayRef<int64_t>> shape,
                       Type elementType) const;

  /// Return true if the specified element type is ok in a tensor.
  static bool isValidElementType(Type type);

  /// Methods for support type inquiry through isa, cast, and dyn_cast.
  static bool classof(Type type);

  /// Allow implicit conversion to ShapedType.
  operator ShapedType() const { return cast<ShapedType>(); }
};
```

通过value获取相关信息如下：

``` c++
mlir::Type type = value.getType(); // get mlir::Type
mlir::TensorType tensor_type = type.cast<mlir::TensorType>(); // cast to tensor type
ArrayRef<int64_t> shape = tensor_type.getShape(); // get shape
mlir::Type eleType = tensor_type.getElementType();
assert(eleType.isF64() == true);
```



#### RankedTensorType 与 UnrankedTensorType

如`tensor<*xfp32>`，对应的是UnrankedTensorType；RankedTensorType有如下这些形式：

```json
// Known rank but unknown dimensions.
tensor<? x ? x ? x ? x f32>
// Partially known dimensions.
tensor<? x ? x 13 x ? x f32>
// Full static shape.
tensor<17 x 4 x 13 x 4 x f32>
// Tensor with rank zero. Represents a scalar.
tensor<f32>
// Zero-element dimensions are allowed.should be optimized away before lowering tensors to vectors
tensor<0 x 42 x f32>
```

使用方法举例：

``` c++
// create
mlir::Type getType(ArrayRef<int64_t> shape) {
  // If the shape is empty, then this type is unranked.
  if (shape.empty())
    return mlir::UnrankedTensorType::get(builder.getF64Type());

  // Otherwise, we use the given shape.
  return mlir::RankedTensorType::get(shape, builder.getF64Type());
}
```



## mlir::MLIRContext

mlir上下文，可以理解成一系列对象的最顶层。所有mlir相关对象都依赖MLIRContext。

## mlir::Builder

用于创建全局对象的建造者，比如创建types、attributes等等，声明如下：

``` c++
class Builder {
public:
  explicit Builder(MLIRContext *context) : context(context) {}
  explicit Builder(Operation *op) : Builder(op->getContext()) {}

  MLIRContext *getContext() const { return context; }

  // Locations.
  Location getUnknownLoc();
  // Types.
  FloatType getBF16Type();
  FloatType getF16Type();
  FloatType getF32Type();
  FloatType getF64Type();
  IntegerType getIntegerType(unsigned width);
  IntegerType getIntegerType(unsigned width, bool isSigned);
  // Attributes.
  NamedAttribute getNamedAttr(StringRef name, Attribute val);
  UnitAttr getUnitAttr();
  BoolAttr getBoolAttr(bool value);
  DictionaryAttr getDictionaryAttr(ArrayRef<NamedAttribute> value);
  IntegerAttr getIntegerAttr(Type type, int64_t value);
  IntegerAttr getIntegerAttr(Type type, const APInt &value);
  FloatAttr getFloatAttr(Type type, double value);
  FloatAttr getFloatAttr(Type type, const APFloat &value);
  StringAttr getStringAttr(const Twine &bytes);
  ArrayAttr getArrayAttr(ArrayRef<Attribute> value);
  // Convenience methods for fixed types.
  FloatAttr getF16FloatAttr(float value);
  FloatAttr getF32FloatAttr(float value);
  FloatAttr getF64FloatAttr(double value);
  IntegerAttr getI8IntegerAttr(int8_t value);
  IntegerAttr getI16IntegerAttr(int16_t value);
  IntegerAttr getI32IntegerAttr(int32_t value);
  ArrayAttr getI32ArrayAttr(ArrayRef<int32_t> values);
  ArrayAttr getF32ArrayAttr(ArrayRef<float> values);
```

#### OpBuilder

继承Builder，用于创建Operation。

有如下接口：

```c++
/// Create an operation of specific op type at the current insertion point.
template <typename OpTy, typename... Args>
OpTy create(Location location, Args &&...args) {
  OperationState state(location,
  getCheckRegisteredInfo<OpTy>(location.getContext()));
  OpTy::build(*this, state, std::forward<Args>(args)...);
  auto *op = createOperation(state);
  auto result = dyn_cast<OpTy>(op);
  assert(result && "builder didn't return the right type");
  return result;
}
```

以`onnx-mlir`的一段代码为例，创建OP如下：

``` c++
auto gemmOp = builder.create<ONNXGemmOp>(UnknownLoc::get(&ctx),
                                         /*Y=*/yType, /*A=*/aVal, /*B=*/bVal, /*C=*/cVal, alphaAttr, betaAttr,
                                         aTransAttr, bTransAttr);
gemmOp.getResult().setType(yType);

llvm::SmallVector<Value, 1> results = {gemmOp.getResult()};
builder.create<ReturnOp>(UnknownLoc::get(&ctx), results);
```



# Dialect的使用

``` c#
def ONNXAddOp:ONNX_Op<"Add",
  [NoSideEffect, DeclareOpInterfaceMethods<ShapeInferenceOpInterface>]> {
  let hasCanonicalizer = 1;
  let summary = "ONNX Add operation";
  let description = [{
  "Performs element-wise binary addition (with Numpy-style broadcasting support)."
  ""
  "This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md)."
  }];
  let arguments = (ins AnyTypeOf<[TensorOf<[UI32]>, TensorOf<[UI64]>, TensorOf<[I32]>, TensorOf<[I64]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>, TensorOf<[BF16]>, AnyMemRef]>:$A,
    AnyTypeOf<[TensorOf<[UI32]>, TensorOf<[UI64]>, TensorOf<[I32]>, TensorOf<[I64]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>, TensorOf<[BF16]>, AnyMemRef]>:$B);
  let results = (outs AnyTypeOf<[TensorOf<[UI32]>, TensorOf<[UI64]>, TensorOf<[I32]>, TensorOf<[I64]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>, TensorOf<[BF16]>, AnyMemRef]>:$C);
  let builders = [
    OpBuilder<(ins "Value":$A, "Value":$B), [{
      auto lhsTy = A.getType();
      auto rhsTy = B.getType();
      auto elementType = getBroadcastedRankedType(lhsTy, rhsTy);
      auto shapedType = elementType.dyn_cast_or_null<ShapedType>();
      if (!shapedType || !shapedType.hasStaticShape()) {
            elementType = A.getType().cast<ShapedType>().getElementType();
            elementType = UnrankedTensorType::get(elementType);
      }
      build($_builder, $_state, elementType, A, B);
    }]>,
    OpBuilder<(ins "ValueRange":$operands, "ArrayRef<NamedAttribute>":$attributes), [{
      auto lhsTy = operands[0].getType();
      auto rhsTy = operands[1].getType();
      auto elementType = getBroadcastedRankedType(lhsTy, rhsTy);
      auto shapedType = elementType.dyn_cast_or_null<ShapedType>();
      if (!shapedType || !shapedType.hasStaticShape()) {
            elementType = operands[0].getType().cast<ShapedType>().getElementType();
            elementType = UnrankedTensorType::get(elementType);
      }
      std::vector<mlir::Type> outputTypes;
      outputTypes.emplace_back(elementType);
      build($_builder, $_state, outputTypes, operands, attributes);
    }]>
    ];
    let extraClassDeclaration = [{
      static int getNumberOfOperands() {
        return 2;
      }
      static int getNumberOfResults() {
        return 1;
      }
      static std::vector<int> getTypeMap() {
        return {20};
      }
    }];
}
```



# 编程技术

## RTTI

阅读：[[How to set up LLVM-style RTTI for your class hierarchy](https://llvm.org/docs/HowToSetUpLLVMStyleRTTI.html#how-to-set-up-llvm-style-rtti-for-your-class-hierarchy)

llvm有这些RTTI接口可以使用`isa<>`、`dyn_cast<>`、`cast<>`等等。

使用这些接口，父类和子列有这些要求：

* 父类：定义Kind枚举，且构造函数用Kind做入参
* 子列：构造函数指定kind，且定义classof接口

<!--more-->

范例如下

``` c++
#include "llvm/Support/Casting.h" 
class Shape {
 public:
   /// Discriminator for LLVM-style RTTI (dyn_cast<> et al.)
   enum ShapeKind {
     SK_Square,
     SK_Circle
   };
 private:
   const ShapeKind Kind;
 public:
   ShapeKind getKind() const { return Kind; }

   Shape(ShapeKind K) : Kind(K) {}
   virtual double computeArea() = 0;
 };

 class Square : public Shape {
   double SideLength;
 public:
   Square(double S) : Shape(SK_Square), SideLength(S) {}
   double computeArea() override;

   static bool classof(const Shape *S) {
     return S->getKind() == SK_Square;
   }
 };

 class Circle : public Shape {
   double Radius;
 public:
   Circle(double R) : Shape(SK_Circle), Radius(R) {}
   double computeArea() override;
 
   static bool classof(const Shape *S) {
     return S->getKind() == SK_Circle;
   }
 };
```

使用参考如下：

``` c++
Shape *S = ...;
if (isa<Circle>(S)) {
  /* do something ... */
}
```



## Traits

阅读：[Traits](https://mlir.llvm.org/docs/Traits/) 与 [C++ traits技术浅谈 ](https://www.cnblogs.com/mangoyuan/p/6446046.html)

traits，被叫做特性萃取技术，提取“被传进的对象”对应的返回类型，让同一个接口实现对应的功能。

MLIR中traits基类是：`TraitBase<ConcreteType, TraitType>`。子类有这几种：`AttributeTrait`、`OpTrait`、`TypeTrait`等等。

其中ConcreteType对应绑定到该trait的实体类，TraitType对应trait类。

### Trait步骤

1 定义Trait。Trait类定义举例如下：

``` c++
template <typename ConcreteType>
class MyTrait : public OpTrait::TraitBase<ConcreteType, MyTrait> {
public:
  /// Override the 'verifyTrait' hook to add additional verification on the
  /// concrete operation.
  static LogicalResult verifyTrait(Operation *op) {
    // ...
  }
};
```

2 绑定Tait。举例如下：

``` c++
class MyOp : public Op<MyOp, MyTrait> {};
```

3 使用Trait。举例如下：

``` c++
Operation *op = ..;
if (op->hasTrait<MyTrait>())
  ...;
```

### CastOp举例

CastOp定义如下：

```c++
def CastOp : Toy_Op<"cast", [
     DeclareOpInterfaceMethods<CastOpInterface>,
     DeclareOpInterfaceMethods<ShapeInferenceOpInterface>,
     NoSideEffect,
     SameOperandsAndResultShape
  ]> {
  let summary = "shape cast operation";
  ...;
```

该op用了4个trait，这四个trait可以分两类，一类是通用类，NoSideEffect与SameOperandsAndResultShape；一类是专用类，通过DeclareOpInterfaceMethods声明的CastOpInterface与ShapeInferenceOpInterface。

这两类有两点区别：

* 通用类，对所有OP都可以使用，不需要专门为op定义相应的接口；专用类，需用对特定OP定义特定的接口。

* 通用类，会被mlir内部直接调用；专用类，需要显示调用

* 判断方法上不同，如下：

  ``` c++
  Operation *op = ..;
  if (op->hasTrait<NoSideEffect>())
    ...;
  if (isa<ShapeInferenceOpInterface>())
    ...;
  ```

  

TableGen生成的代码如下：

``` c++
class CastOpAdaptor {
public:
  CastOpAdaptor(::mlir::ValueRange values, ::mlir::DictionaryAttr attrs = nullptr, ::mlir::RegionRange regions = {});

  CastOpAdaptor(CastOp &op);
  ...;
};

class CastOp : public ::mlir::Op<CastOp, ::mlir::OpTrait::ZeroRegion, ::mlir::OpTrait::OneResult, ::mlir::OpTrait::OneTypedResult<::mlir::TensorType>::Impl, ::mlir::OpTrait::ZeroSuccessor, ::mlir::OpTrait::OneOperand, ::mlir::CastOpInterface::Trait, ShapeInference::Trait, ::mlir::MemoryEffectOpInterface::Trait, ::mlir::OpTrait::SameOperandsAndResultShape> {
public:
  using Op::Op;
  using Op::print;
  using Adaptor = CastOpAdaptor;
public:
  ...;
```

### ShapeInferenceOpInterface

定义如下：

``` c++
def ShapeInferenceOpInterface : OpInterface<"ShapeInference"> {
  let description = [{
    Interface to access a registered method to infer the return types for an
    operation that can be used during type inference.
  }];

  let methods = [
    InterfaceMethod<"Infer and set the output shape for the current operation.",
                    "void", "inferShapes">
  ];
}
```

所以castOp需要实现inferShapes接口，如下：

``` c++
void CastOp::inferShapes() { getResult().setType(getOperand().getType()); }
```

### CastOpInterface

``` c++
def CastOpInterface : OpInterface<"CastOpInterface"> {
  let description = [{
    A cast-like operation is one that converts from a set of input types to a
    set of output types. The arity of the inputs may be from 0-N, whereas the
    arity of the outputs may be anything from 1-N. Cast-like operations are
    trivially removable in cases where they produce an No-op, i.e when the
    input types and output types match 1-1.
  }];
  let cppNamespace = "::mlir";

  let methods = [
    StaticInterfaceMethod<[{
        Returns true if the given set of input and result types are compatible
        to cast using this cast operation.
      }],
      "bool", "areCastCompatible",
      (ins "::mlir::TypeRange":$inputs, "::mlir::TypeRange":$outputs)
    >,
  ];
  ...;
}
```

所以castOp需要实现areCastCompatible接口：

```  c++
bool CastOp::areCastCompatible(TypeRange inputs, TypeRange outputs) {
  if (inputs.size() != 1 || outputs.size() != 1)
    return false;
  // The inputs must be Tensors with the same element type.
  TensorType input = inputs.front().dyn_cast<TensorType>();
  TensorType output = outputs.front().dyn_cast<TensorType>();
  if (!input || !output || input.getElementType() != output.getElementType())
    return false;
  // The shape is required to match if both types are ranked.
  return !input.hasRank() || !output.hasRank() || input == output;
}
```

#### SameOperandsAndResultShape

op中加入对所有的输入输出shape校验，确保所有的输入输出shape相同。

`OpDefinition.h`中定义如下：

``` c++
template <typename ConcreteType>
class SameOperandsAndResultShape
    : public TraitBase<ConcreteType, SameOperandsAndResultShape> {
public:
  static LogicalResult verifyTrait(Operation *op) {
    return impl::verifySameOperandsAndResultShape(op);
  }
};
```

`OpBase.td`中定义如下：

``` c++
// Op has same operand and result shape.
def SameOperandsAndResultShape : NativeOpTrait<"SameOperandsAndResultShape">;
```

其中还有很多校验类trait被定义如下：

```c++
def ConstantLike : NativeOpTrait<"ConstantLike">;
// Op is isolated from above.
def IsolatedFromAbove : NativeOpTrait<"IsIsolatedFromAbove">;
// Op results are float or vectors/tensors thereof.
def ResultsAreFloatLike : NativeOpTrait<"ResultsAreFloatLike">;
// Op has the same operand type.
def SameTypeOperands : NativeOpTrait<"SameTypeOperands">;
// Op has same shape for all operands.
def SameOperandsShape : NativeOpTrait<"SameOperandsShape">;
// Op's regions have a single block.
def SingleBlock : NativeOpTrait<"SingleBlock">;
```

#### NoSideEffect

在`include/mlir/Interfaces/SideEffectInterfaces.td`中定义，表示不需要做消除副作用的处理，如下：

``` c++
void CastOp::getEffects(::mlir::SmallVectorImpl<::mlir::SideEffects::EffectInstance<::mlir::MemoryEffects::Effect>> &effects) {
}
```

什么情况下需要做消除副作用的处理，还不得而知。

